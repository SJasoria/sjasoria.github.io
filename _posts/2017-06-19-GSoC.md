---
layout: post
title: Google Summer of Code with Mozilla
subtitle: And the work done so far
tags: [mozilla, sfallhands, gsoc, perfherder]
---
<figure>
	<img src="/images/sfallhandsblue.jpg" >
</figure>

India lost finals of Champions Trophy. *sob sob*   

At the same time, I’m super excited because I’m going to San Francisco next week for the Mozilla All Hands.
 
As promised in my last (or first?) post, I'll describe my GSoC project in this one. 
 
I have been contributing to Perfherder for almost a year, starting with [Quarter of Contribution](https://wlach.github.io/blog/2016/08/perfherder-quarter-of-contribution-summer-2016-results/) last summer to Google Summer of Code this year. Perfherder is performance analysis dashboard which helps keep the performance of Mozilla's products top notch. With the help of my mentor [William Lachance](https://mozillians.org/en-US/u/wlach/), I have added and improved various features of Perfherder.

### The Challenge  
This summer, I'll make a view to visualise results of performance tests run against Mozilla's products. Currently, Perfherder provides aggregated results and graphical visualisation of various test suites, but not for the individual test numbers (internally called “replicates”) that are used to generate them. For tests where there is a large natural variation in these individual numbers, it can be difficult to determine whether there is a regression or not. This is when visualising distribution of replicates would come in handy.

### The Foe
``` javascript
$q.all(promises).then(...)
```
Keeping up with promises is tough. :P

### Work Done So Far

In last twenty days of GSoC, I have squashed two big bugs and a few small ones:  
+ [Bug 1273513](https://bugzilla.mozilla.org/show_bug.cgi?id=1273513)

	Initially, Perfherder allowed comparing data for two specific revisions for the available projects. Due to this, more talos runs had to be triggered in order to gain confidence in the results. Inspired from the e10s pane, this bug enabled Perfherder to pull data for a larger number of runs for the base project.

+ [Bug 1164891](https://bugzilla.mozilla.org/show_bug.cgi?id=1164891)

	This bug enabled to visualise the distribution of values obtained from multiple test runs. This will be useful for tests like ts_paint, paint, sessionrestore where there is a large amount of noise which makes it difficult to identify regression.
	{% capture images %}
		/images/1164891after.png
		/images/1164891before.png
	{% endcapture %}
	{% include gallery images=images caption="Bug 1164891: Distribution of range of numbers can now be seen" cols=2 align="center" %}
 
That’s it for now. My next blog would be about the Mozilla All Hands and [Bug 1350384](https://bugzilla.mozilla.org/show_bug.cgi?id=1350384) which constitutes the larger part of my project.
 
Until then. :)

